services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.app
    container_name: app
    environment:
      # MinIO config pour Spark
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123

      # Luigi
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio123
      LUIGI_S3_ENDPOINT: http://minio:9000

      # MLflow
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_ARTIFACT_URI: s3://mlflow-artifacts

      ## MLflow attend un dépôt Git
      GIT_PYTHON_REFRESH: quiet

      # Spark / Java options pour compatibilité JDK >= 17
      PYSPARK_SUBMIT_ARGS: --conf spark.driver.extraJavaOptions=--add-opens=java.base/javax.security.auth=ALL-UNNAMED pyspark-shell
      JAVA_TOOL_OPTIONS: --enable-native-access=ALL-UNNAMED

      # Kaggle
      KAGGLEHUB_CACHE_DIR: /app/.cache/kagglehub
      HOME: /app

    ports:
      - "4040-4050:4040-4050"
      - "8082:8082"
    volumes:
      - .:/app
    depends_on:
      - minio_fs
      - mlflow
    networks:
      - ml_pr_network

  minio_fs:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"
    networks:
      - ml_pr_network

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: mlflow
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio123
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    command: [
      "mlflow", "server",
      "--backend-store-uri", "sqlite:///mlflow.db",
      "--default-artifact-root", "s3://mlflow-artifacts",
      "--host", "0.0.0.0"
    ]
    ports:
      - "5000:5000"
    depends_on:
      - minio_fs
    networks:
      - ml_pr_network

volumes:
  minio_data:

networks:
  ml_pr_network:
